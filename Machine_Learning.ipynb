{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below will be a basic model including all of the features I collected for school districts. As mentioned in the Data Analysis notebook, I beleive the model will suffer from multicollinearity. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                 \n",
      "=========================================================================================\n",
      "Dep. Variable:     Graduated 4-Year (%)   R-squared (uncentered):                   0.960\n",
      "Model:                              OLS   Adj. R-squared (uncentered):              0.959\n",
      "Method:                   Least Squares   F-statistic:                              794.8\n",
      "Date:                  Sun, 15 Mar 2020   Prob (F-statistic):                   1.74e-267\n",
      "Time:                          15:06:36   Log-Likelihood:                         -1437.9\n",
      "No. Observations:                   406   AIC:                                      2900.\n",
      "Df Residuals:                       394   BIC:                                      2948.\n",
      "Df Model:                            12                                                  \n",
      "Covariance Type:              nonrobust                                                  \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ACT-Composite                       2.5437      0.610      4.170      0.000       1.344       3.743\n",
      "ACT-Part_Rate                       0.0408      0.037      1.099      0.273      -0.032       0.114\n",
      "AP-11&12 Participating Students    -0.0027      0.004     -0.632      0.528      -0.011       0.006\n",
      "AP-Total Exams                      0.0023      0.002      1.493      0.136      -0.001       0.005\n",
      "AP-Passed(%)                        0.3034      0.038      8.033      0.000       0.229       0.378\n",
      "AP-Exams Taken Per Student         -5.2097      1.603     -3.251      0.001      -8.360      -2.059\n",
      "Enrolled 4-Year                     0.0070      0.006      1.183      0.238      -0.005       0.019\n",
      "Total Graduated                    -0.0037      0.002     -2.248      0.025      -0.007      -0.000\n",
      "Enrolled 4-Year (%)                -0.4181      0.132     -3.172      0.002      -0.677      -0.159\n",
      "SAT-Total                          -0.0061      0.012     -0.531      0.596      -0.029       0.017\n",
      "SAT-Part_Rate                      -0.0313      0.041     -0.763      0.446      -0.112       0.049\n",
      "Wealth/ADA                      -6.521e-07    2.5e-06     -0.261      0.794   -5.57e-06    4.27e-06\n",
      "==============================================================================\n",
      "Omnibus:                        9.831   Durbin-Watson:                   1.953\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               13.564\n",
      "Skew:                           0.202   Prob(JB):                      0.00113\n",
      "Kurtosis:                       3.799   Cond. No.                     1.76e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.76e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### Interpreting Coefficients, Stats Model OLS ###\n",
    "from statsmodels.api import OLS\n",
    "grad = pd.read_csv('Feature_Target_Data.csv')\n",
    "years = [2011, 2012, 2013, 2014]\n",
    "grad = grad.loc[grad['Year'].isin(years)]\n",
    "grad = grad[grad.columns[3:]]\n",
    "X = grad[grad.columns[:-1]]\n",
    "y = grad[grad.columns[-1]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "olsreg = OLS(y_train, X_train)\n",
    "olsreg = olsreg.fit()\n",
    "print(olsreg.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "As seen from Warning 2, the basic model is indeed dealing with multicollinearity. \n",
    "\n",
    "From Data Analysis notebook, below are features with that contain high correlations with other features that we can consider dropping to benefit our regression model\n",
    "\n",
    "['AP-Total Exams', 'AP-Passed(%)', 'Enrolled 4-Year', 'Total Graduated', 'SAT-Total']\n",
    "\n",
    "When thinking from a significance standpoint, we could also explore excluding 'Wealth/ADA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                 \n",
      "=========================================================================================\n",
      "Dep. Variable:     Graduated 4-Year (%)   R-squared (uncentered):                   0.959\n",
      "Model:                              OLS   Adj. R-squared (uncentered):              0.958\n",
      "Method:                   Least Squares   F-statistic:                              1544.\n",
      "Date:                  Sun, 15 Mar 2020   Prob (F-statistic):                   4.71e-273\n",
      "Time:                          15:06:41   Log-Likelihood:                         -1446.6\n",
      "No. Observations:                   406   AIC:                                      2905.\n",
      "Df Residuals:                       400   BIC:                                      2929.\n",
      "Df Model:                             6                                                  \n",
      "Covariance Type:              nonrobust                                                  \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "ACT-Composite                  2.0525      0.148     13.900      0.000       1.762       2.343\n",
      "ACT-Part_Rate                  0.0671      0.035      1.906      0.057      -0.002       0.136\n",
      "AP-Passed(%)                   0.3444      0.032     10.846      0.000       0.282       0.407\n",
      "AP-Exams Taken Per Student    -5.6603      1.322     -4.282      0.000      -8.259      -3.062\n",
      "Enrolled 4-Year (%)           -0.3690      0.112     -3.309      0.001      -0.588      -0.150\n",
      "SAT-Part_Rate                 -0.0344      0.038     -0.912      0.362      -0.109       0.040\n",
      "==============================================================================\n",
      "Omnibus:                       11.442   Durbin-Watson:                   1.935\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               17.424\n",
      "Skew:                           0.200   Prob(JB):                     0.000165\n",
      "Kurtosis:                       3.933   Cond. No.                         274.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### Studying Effects of Dropping Certain Features Due to Multicollinearity/Domain Insignificance ###\n",
    "grad = grad.drop(['AP-Total Exams', 'Enrolled 4-Year', 'Total Graduated', 'AP-11&12 Participating Students', 'SAT-Total', 'Wealth/ADA'], axis=1)\n",
    "X = grad[grad.columns[:-1]]\n",
    "y = grad[grad.columns[-1]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "olsreg = OLS(y_train, X_train)\n",
    "olsreg = olsreg.fit()\n",
    "print(olsreg.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Warning about Multicollinearity is gone ^ and R2 decreased from .96 to .959 (not terrible)\n",
    "\n",
    "Below we'll test out linear regression in scikit learn and view resulting RMSE, r2, and MAPE metrics to see if the model performs better with all features or without the features causing multicollinearity. I'll use several different testing sizes and 100 different random states for each testing size. I'll then take the average metric scores for each testing size for all features and after dropping certain features. \n",
    "\n",
    "Here I'm trying to eliminate bias for how the data was split up into training and testing sets to make a reasonable conclusion on how dropping certain features affects model performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Test Size:  0.275 ***\n",
      "*All Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.024981633156637 r2:  0.5808002398725814 MAPE:  17.746177379426808\n",
      "\n",
      "Best RMSE:  6.5780572094757215 Random State:  657\n",
      "Best r2:  0.7024134573472549 Random State:  926\n",
      "Best MAPE:  13.670654224423245 Random State:  178\n",
      "\n",
      "*After Dropping Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.134285510326231 r2:  0.5693447328370037 MAPE:  17.785877371894035\n",
      "\n",
      "Best RMSE:  6.501762627984149 Random State:  319\n",
      "Best r2:  0.7178792180167728 Random State:  319\n",
      "Best MAPE:  13.453253962546366 Random State:  178\n",
      "\n",
      "***Test Size:  0.25 ***\n",
      "*All Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.017852279775068 r2:  0.5806564816476749 MAPE:  17.71832721888505\n",
      "\n",
      "Best RMSE:  6.38238954547272 Random State:  118\n",
      "Best r2:  0.7024513998328827 Random State:  926\n",
      "Best MAPE:  13.474187318294028 Random State:  178\n",
      "\n",
      "*After Dropping Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.123081563758923 r2:  0.5696434780249183 MAPE:  17.75043229817592\n",
      "\n",
      "Best RMSE:  6.378626753500852 Random State:  118\n",
      "Best r2:  0.7209473245336535 Random State:  319\n",
      "Best MAPE:  13.071751706195379 Random State:  62\n",
      "\n",
      "***Test Size:  0.225 ***\n",
      "*All Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.005915792326032 r2:  0.5810784202910876 MAPE:  17.70408917841048\n",
      "\n",
      "Best RMSE:  6.264752580606269 Random State:  118\n",
      "Best r2:  0.710539569554083 Random State:  319\n",
      "Best MAPE:  13.103722876512522 Random State:  266\n",
      "\n",
      "*After Dropping Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.112715162377897 r2:  0.5698807229270929 MAPE:  17.74225007663305\n",
      "\n",
      "Best RMSE:  6.222089377106793 Random State:  985\n",
      "Best r2:  0.727564682939494 Random State:  319\n",
      "Best MAPE:  12.821798487264257 Random State:  62\n",
      "\n",
      "***Test Size:  0.2 ***\n",
      "*All Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  7.993381752803343 r2:  0.581235694163175 MAPE:  17.685344945329568\n",
      "\n",
      "Best RMSE:  6.198273680954995 Random State:  639\n",
      "Best r2:  0.7441823938418632 Random State:  639\n",
      "Best MAPE:  13.141485517453438 Random State:  266\n",
      "\n",
      "*After Dropping Features: Performance on Test Set*\n",
      "\n",
      "Average Results from different Random States:\n",
      "RMSE:  8.101765580468637 r2:  0.5698547553143269 MAPE:  17.730206958162714\n",
      "\n",
      "Best RMSE:  6.34294597637801 Random State:  118\n",
      "Best r2:  0.7256397467755512 Random State:  103\n",
      "Best MAPE:  12.314523481376586 Random State:  62\n"
     ]
    }
   ],
   "source": [
    "########## Linear Regression Model for Predicting Graduated 4-Year (%) ############\n",
    "\n",
    "### USING DIFFERENT RANDOM STATES AND DIFFERENT TEST SPLITS ####\n",
    "\n",
    "### ALL Features ###\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "for test_size in [.275, .25, .225, .2]:\n",
    "    rmse_all = []\n",
    "    r2_all = []\n",
    "    mape_all = []\n",
    "    rmse_drop = []\n",
    "    r2_drop = []\n",
    "    mape_drop = []\n",
    "    print('\\n***Test Size: ', test_size, '***')\n",
    "    for i in range(1000):\n",
    "        grad = pd.read_csv('Feature_Target_Data.csv')\n",
    "        years = [2011, 2012, 2013, 2014]\n",
    "        grad = grad.loc[grad['Year'].isin(years)]\n",
    "        grad = grad[grad.columns[3:]]\n",
    "        X = grad.drop('Graduated 4-Year (%)', axis=1).values\n",
    "        y = grad['Graduated 4-Year (%)'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=i)\n",
    "        linear_reg = LinearRegression()\n",
    "        linear_reg.fit(X_train, y_train)\n",
    "        y_pred_test = linear_reg.predict(X_test)\n",
    "        y_pred_train = linear_reg.predict(X_train)\n",
    "        rmse_all.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "        r2_all.append(linear_reg.score(X_test, y_test))\n",
    "        mape_all.append(mean_absolute_percentage_error(y_test, y_pred_test))\n",
    "        r2_max_index = r2_all.index(np.max(r2_all))        \n",
    "        rmse_max_index = rmse_all.index(np.min(rmse_all))\n",
    "        mape_max_index = mape_all.index(np.min(mape_all))\n",
    "        ### After Dropping Features Causing Mulicollinearity ###\n",
    "        X2 = grad.drop(['Graduated 4-Year (%)', 'AP-Total Exams', 'Enrolled 4-Year', 'Total Graduated', 'AP-11&12 Participating Students', 'SAT-Total', 'Wealth/ADA'], axis=1).values\n",
    "        y2 = grad['Graduated 4-Year (%)'].values\n",
    "        X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=test_size, random_state=i)\n",
    "        linear_reg = LinearRegression()\n",
    "        linear_reg.fit(X_train2, y_train2)\n",
    "        y_pred_test2 = linear_reg.predict(X_test2)\n",
    "        y_pred_train2 = linear_reg.predict(X_train2)\n",
    "        rmse_drop.append(np.sqrt(mean_squared_error(y_test2, y_pred_test2)))\n",
    "        r2_drop.append(linear_reg.score(X_test2, y_test2))\n",
    "        mape_drop.append(mean_absolute_percentage_error(y_test2, y_pred_test2))\n",
    "        r2_max_index2 = r2_drop.index(np.max(r2_drop))        \n",
    "        rmse_max_index2 = rmse_drop.index(np.min(rmse_drop))\n",
    "        mape_max_index2 = mape_drop.index(np.min(mape_drop))\n",
    "    print('*All Features: Performance on Test Set*')\n",
    "    print('\\nAverage Results from different Random States:')\n",
    "    print('RMSE: ', np.mean(rmse_all), 'r2: ', np.mean(r2_all), 'MAPE: ', np.mean(mape_all))\n",
    "    print('\\nBest RMSE: ', rmse_all[rmse_max_index], 'Random State: ', rmse_max_index)\n",
    "    print('Best r2: ', r2_all[r2_max_index], 'Random State: ', r2_max_index)\n",
    "    print('Best MAPE: ', mape_all[mape_max_index], 'Random State: ', mape_max_index)\n",
    "\n",
    "    print('\\n*After Dropping Features: Performance on Test Set*')\n",
    "    print('\\nAverage Results from different Random States:')\n",
    "    print('RMSE: ', np.mean(rmse_drop), 'r2: ', np.mean(r2_drop), 'MAPE: ', np.mean(mape_drop))\n",
    "    print('\\nBest RMSE: ', rmse_drop[rmse_max_index2], 'Random State: ', rmse_max_index2)\n",
    "    print('Best r2: ', r2_drop[r2_max_index2], 'Random State: ', r2_max_index2)\n",
    "    print('Best MAPE: ', mape_drop[mape_max_index2], 'Random State: ', mape_max_index2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Above I used 1000 different possible random states and printed out the respective results (average of random states) for all features versus dropping some features. For all the different testing sizes and random states, I can not reasonably say that dropping certain features will result in a better performing model. \n",
    "\n",
    "I also provided the best results for each case to use going forward as our goal is to get the best performing model. Once again, we cant see a consistent trend in the difference between the best scores for all features versus dropping select features. \n",
    "\n",
    "In terms of best model performance, I will use all available features, testing size of .2, and random state of 639. R2 and RMSE was the best for these parameters. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "********* SUMMARY OF ALL THE ABOVE CELLS/EXERCISES *********************\n",
    "\n",
    "1. \n",
    "I started with an OLS model in which I utilized all of the features I collected. I utilized a 75 - 25 split and a random state of 42. After training and fitting the model, I printed out a summary of the OLS model in which R2 was .96\n",
    "I also received a multicollinearity warning in the summary as the condition number was too high. \n",
    "\n",
    "2. \n",
    "After finding the features that are causing the collinearity in the Data Analysis notebook, I dropped the features and repeated (1) with the same train test split and random state. I found that R2 barely decreased from .96 to .959 and that the multicollinearity warning was gone. \n",
    "\n",
    "3. \n",
    "I then utilized linear regression in scikit learn to the view resulting RMSE, r2, and MAPE metrics for evaluating model performance with all features versus without the features causing multicollinearity. I used several different testing sizes and 100 different random states for each testing size. I then took the average metric scores for each testing size for all features and after dropping certain features. I did this to eliminate bias for how the data was split up into training and testing sets to make a reasonable conclusion on how dropping certain features affects model performance. \n",
    "\n",
    "For all the different testing sizes and random states, I can not reasonably say that dropping certain features will result in a better performing model. \n",
    "\n",
    "I also provided the best results for each case to use going forward as our goal is to get the best performing model. Once again, we cant see a consistent trend in the difference between the best scores for all features versus dropping select features. \n",
    "\n",
    "In terms of best model performance, I will use all available features, testing size of .2, and random state of 639. R2 and RMSE was the best for these parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Training RMSE: 8.205665471245794 Testing RMSE: 6.198273680955048\n",
      "\n",
      "Training R2:  0.5754095033931913 Testing R2:  0.7441823938418588\n",
      "\n",
      "Training MAPE:  18.109866126554923 Testing MAPE:  14.549309277352723\n",
      "\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Training RMSE: 8.205669056585874 Testing RMSE: 6.198721955015161\n",
      "\n",
      "Training R2:  0.5754091323564576 Testing R2:  0.7441453898147055\n",
      "\n",
      "Training MAPE:  18.109189420233786 Testing MAPE:  14.554301954466315\n",
      "\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Training RMSE: 8.2374949316565 Testing RMSE: 6.239775007211057\n",
      "\n",
      "Training R2:  0.5721091744835733 Testing R2:  0.740745206829085\n",
      "\n",
      "Training MAPE:  18.012894440793335 Testing MAPE:  14.813833443845095\n"
     ]
    }
   ],
   "source": [
    "#### Evaluating Ridge and Lasso Model Performance ####\n",
    "### ALSO ADDING SCALER (Robust Gave Best Results) ###\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, Normalizer, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "grad = pd.read_csv('Feature_Target_Data.csv')\n",
    "years = [2011, 2012, 2013, 2014]\n",
    "grad = grad.loc[grad['Year'].isin(years)]\n",
    "grad = grad[grad.columns[3:]]\n",
    "X = grad.drop('Graduated 4-Year (%)', axis=1).values\n",
    "y = grad['Graduated 4-Year (%)'].values\n",
    "linear_reg = LinearRegression()\n",
    "steps = [('scaler', RobustScaler()), ('reg', LinearRegression())]\n",
    "reg = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=639)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_train = reg.predict(X_train)\n",
    "y_pred_test = reg.predict(X_test)\n",
    "print('Linear Regression')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)), 'Testing RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('\\nTraining R2: ', reg.score(X_train, y_train), 'Testing R2: ', reg.score(X_test, y_test))\n",
    "print('\\nTraining MAPE: ', mean_absolute_percentage_error(y_train, y_pred_train), 'Testing MAPE: ', mean_absolute_percentage_error(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "\n",
    "for regression_model in [Ridge(), Lasso()]:\n",
    "    print('\\n' + str(regression_model))\n",
    "    steps = [('scaler', RobustScaler()), ('reg', regression_model)]\n",
    "    pipeline = Pipeline(steps)\n",
    "    params = {'reg__alpha': [.00001, .0001, .001, .01, .1]}\n",
    "    reg = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred_train = reg.predict(X_train)\n",
    "    y_pred_test = reg.predict(X_test)\n",
    "    print('Training RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)), 'Testing RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    print('\\nTraining R2: ', reg.score(X_train, y_train), 'Testing R2: ', reg.score(X_test, y_test))\n",
    "    print('\\nTraining MAPE: ', mean_absolute_percentage_error(y_train, y_pred_train), 'Testing MAPE: ', mean_absolute_percentage_error(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "In terms of model performance, Ridge and Lasso failed to beat out the linear regression model. While the Linear regression model is the best, I believe a random forest regression will solve many of the concerns with random state. Each tree will draw a random sample from the original data set when generating its splits, adding a further element of randomness that prevents overfitting.\n",
    "\n",
    "The number of features that can be split on at each node is limited to some percentage of the total, which will also help ensures that the ensemble model does not rely too heavily on any individual feature. This makes fair use of all potentially predictive features and helps the issues of multicollinearity explored at the beginning of this notebook. \n",
    "\n",
    "The above modifications help prevent the trees from being too highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.34835846 -5.29251738 -6.38798507 -6.36059789 -6.19471421 -7.54840316\n",
      " -7.00768369 -4.91011749 -6.90779029 -7.5104376 ]\n"
     ]
    }
   ],
   "source": [
    "####### RandomForestRegressor #########\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "grad = pd.read_csv('Feature_Target_Data.csv')\n",
    "years = [2011, 2012, 2013, 2014]\n",
    "grad = grad.loc[grad['Year'].isin(years)]\n",
    "grad = grad[grad.columns[3:]]\n",
    "X = grad.drop('Graduated 4-Year (%)', axis=1).values\n",
    "y = grad['Graduated 4-Year (%)'].values\n",
    "\n",
    "def rand_forest(X, y):\n",
    "    gsc = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "        param_grid={'max_depth': range(2, 7),\n",
    "            'n_estimators': (10, 50, 100, 1000)},\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    grid_result = gsc.fit(X, y)\n",
    "    best_params = grid_result.best_params_\n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], random_state=False, verbose=False)\n",
    "    scores = cross_val_score(rfr, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "    return scores\n",
    "\n",
    "print(rand_forest(X, y))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
