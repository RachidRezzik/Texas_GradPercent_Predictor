{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below will be a basic model including all of the features I collected for school districts. As mentioned in the Data Analysis notebook, I beleive the model will suffer from multicollinearity. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                 \n",
      "=========================================================================================\n",
      "Dep. Variable:     Graduated 4-Year (%)   R-squared (uncentered):                   0.960\n",
      "Model:                              OLS   Adj. R-squared (uncentered):              0.959\n",
      "Method:                   Least Squares   F-statistic:                              744.0\n",
      "Date:                  Fri, 13 Mar 2020   Prob (F-statistic):                   4.51e-250\n",
      "Time:                          16:28:37   Log-Likelihood:                         -1349.1\n",
      "No. Observations:                   381   AIC:                                      2722.\n",
      "Df Residuals:                       369   BIC:                                      2770.\n",
      "Df Model:                            12                                                  \n",
      "Covariance Type:              nonrobust                                                  \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ACT-Composite                       2.2297      0.626      3.563      0.000       0.999       3.460\n",
      "ACT-Part_Rate                       0.0435      0.039      1.124      0.262      -0.033       0.120\n",
      "AP-11&12 Participating Students    -0.0030      0.004     -0.677      0.499      -0.012       0.006\n",
      "AP-Total Exams                      0.0024      0.002      1.530      0.127      -0.001       0.006\n",
      "AP-Passed(%)                        0.3047      0.039      7.852      0.000       0.228       0.381\n",
      "AP-Exams Taken Per Student         -5.5846      1.655     -3.375      0.001      -8.839      -2.331\n",
      "Enrolled 4-Year                     0.0076      0.006      1.272      0.204      -0.004       0.019\n",
      "Total Graduated                    -0.0038      0.002     -2.305      0.022      -0.007      -0.001\n",
      "Enrolled 4-Year (%)                -0.4285      0.135     -3.169      0.002      -0.694      -0.163\n",
      "SAT-Total                           0.0009      0.012      0.073      0.942      -0.022       0.024\n",
      "SAT-Part_Rate                      -0.0274      0.043     -0.636      0.525      -0.112       0.057\n",
      "Wealth/ADA                      -9.625e-07   2.56e-06     -0.376      0.707   -5.99e-06    4.07e-06\n",
      "==============================================================================\n",
      "Omnibus:                       10.559   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.005   Jarque-Bera (JB):               15.096\n",
      "Skew:                           0.215   Prob(JB):                     0.000527\n",
      "Kurtosis:                       3.875   Cond. No.                     1.78e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.78e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### Interpreting Coefficients, Stats Model OLS ###\n",
    "from statsmodels.api import OLS\n",
    "grad = pd.read_csv('Feature_Target_Data.csv')\n",
    "years = [2011, 2012, 2013, 2014]\n",
    "grad = grad.loc[grad['Year'].isin(years)]\n",
    "grad = grad[grad.columns[3:]]\n",
    "X = grad[grad.columns[:-1]]\n",
    "y = grad[grad.columns[-1]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n",
    "olsreg = OLS(y_train, X_train)\n",
    "olsreg = olsreg.fit()\n",
    "print(olsreg.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "As seen from Warning 2, the basic model is indeed dealing with multicollinearity. \n",
    "\n",
    "From Data Analysis notebook, below are features with that contain high correlations with other features that we can consider dropping to benefit our regression model\n",
    "\n",
    "['AP-Total Exams', 'AP-Passed(%)', 'Enrolled 4-Year', 'Total Graduated', 'SAT-Total']\n",
    "\n",
    "When thinking from a significance standpoint, we could also explore excluding 'Wealth/ADA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                 \n",
      "=========================================================================================\n",
      "Dep. Variable:     Graduated 4-Year (%)   R-squared (uncentered):                   0.959\n",
      "Model:                              OLS   Adj. R-squared (uncentered):              0.958\n",
      "Method:                   Least Squares   F-statistic:                              1448.\n",
      "Date:                  Fri, 13 Mar 2020   Prob (F-statistic):                   7.61e-256\n",
      "Time:                          16:28:41   Log-Likelihood:                         -1357.1\n",
      "No. Observations:                   381   AIC:                                      2726.\n",
      "Df Residuals:                       375   BIC:                                      2750.\n",
      "Df Model:                             6                                                  \n",
      "Covariance Type:              nonrobust                                                  \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "ACT-Composite                  2.0954      0.154     13.586      0.000       1.792       2.399\n",
      "ACT-Part_Rate                  0.0679      0.037      1.851      0.065      -0.004       0.140\n",
      "AP-Passed(%)                   0.3358      0.033     10.198      0.000       0.271       0.401\n",
      "AP-Exams Taken Per Student    -5.8357      1.361     -4.286      0.000      -8.513      -3.159\n",
      "Enrolled 4-Year (%)           -0.3652      0.114     -3.202      0.001      -0.589      -0.141\n",
      "SAT-Part_Rate                 -0.0395      0.039     -1.008      0.314      -0.117       0.038\n",
      "==============================================================================\n",
      "Omnibus:                       12.775   Durbin-Watson:                   1.949\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               20.029\n",
      "Skew:                           0.230   Prob(JB):                     4.48e-05\n",
      "Kurtosis:                       4.024   Cond. No.                         274.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### Studying Effects of Dropping Certain Features Due to Multicollinearity/Domain Insignificance ###\n",
    "grad = grad.drop(['AP-Total Exams', 'Enrolled 4-Year', 'Total Graduated', 'AP-11&12 Participating Students', 'SAT-Total', 'Wealth/ADA'], axis=1)\n",
    "X = grad[grad.columns[:-1]]\n",
    "y = grad[grad.columns[-1]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n",
    "olsreg = OLS(y_train, X_train)\n",
    "olsreg = olsreg.fit()\n",
    "print(olsreg.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Warning about Multicollinearity is gone ^, significance of features has gotten better as well.\n",
    "Below we'll test out linear regression in scikit learn and view resulting RMSE, r2, and MAPE to see if the model how much better the model performs with all features and without the features causing multicollinearity/insignificant. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---All Features--- \n",
      "\n",
      "Training RMSE: 8.039580002590322 \n",
      "Testing RMSE: 7.270472881050807\n",
      "\n",
      "Training R2:  0.5845709858118027 \n",
      "Testing R2:  0.6667216573402157\n",
      "\n",
      "Training MAPE:  17.648364646323063 \n",
      "Testing MAPE:  16.839248356026104\n",
      "\n",
      " ---After Dropping Features--- \n",
      "\n",
      "Training RMSE: 8.340827253346166 \n",
      "Testing RMSE: 7.012582803482295\n",
      "\n",
      "Training R2:  0.552855023741984 \n",
      "Testing R2:  0.6899456848554524\n",
      "\n",
      "Training MAPE:  18.27036806499571 \n",
      "Testing MAPE:  15.734016811248416\n"
     ]
    }
   ],
   "source": [
    "########## Linear Regression Model for Predicting Graduated 4-Year (%) ############\n",
    "### ALL Features ###\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "grad = pd.read_csv('Feature_Target_Data.csv')\n",
    "years = [2011, 2012, 2013, 2014]\n",
    "grad = grad.loc[grad['Year'].isin(years)]\n",
    "grad = grad[grad.columns[3:]]\n",
    "X = grad.drop('Graduated 4-Year (%)', axis=1).values\n",
    "y = grad['Graduated 4-Year (%)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred_test = linear_reg.predict(X_test)\n",
    "y_pred_train = linear_reg.predict(X_train)\n",
    "print('---All Features---', '\\n')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)), '\\nTesting RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('\\nTraining R2: ', linear_reg.score(X_train, y_train), '\\nTesting R2: ', linear_reg.score(X_test, y_test))\n",
    "print('\\nTraining MAPE: ', mean_absolute_percentage_error(y_train, y_pred_train), '\\nTesting MAPE: ', mean_absolute_percentage_error(y_test, y_pred_test))\n",
    "\n",
    "### After Dropping Features Causing Mulicollinearity/Insignificance ###\n",
    "X = grad.drop(['Graduated 4-Year (%)', 'AP-Total Exams', 'Enrolled 4-Year', 'Total Graduated', 'AP-11&12 Participating Students', 'SAT-Total', 'Wealth/ADA'], axis=1).values\n",
    "y = grad['Graduated 4-Year (%)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred_test = linear_reg.predict(X_test)\n",
    "y_pred_train = linear_reg.predict(X_train)\n",
    "print('\\n', '---After Dropping Features---', '\\n')\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)), '\\nTesting RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('\\nTraining R2: ', linear_reg.score(X_train, y_train), '\\nTesting R2: ', linear_reg.score(X_test, y_test))\n",
    "print('\\nTraining MAPE: ', mean_absolute_percentage_error(y_train, y_pred_train), '\\nTesting MAPE: ', mean_absolute_percentage_error(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Every metric above appears to improve for the testing set, indicating a better performing model on unseen data in predicting the target (Graduation 4-Year %). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
